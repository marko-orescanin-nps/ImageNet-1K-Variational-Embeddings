# CoastalUncertainty


## Name
Uncertainty aware classification of aerial coastal imagery using probabilistic convolutional neural networks and vision transformers

## Description
This repository contains all project source code as well as a Jupyter Notebook walk-through of different visualizations. This repository is the source code for the IEEE Access paper titled "Uncertainty-Aware Aerial Coastal Imagery Pattern Recognition Through Transfer Learning with ImageNet-1K Variational Embeddings".

## Roadmap
The datasets, model checkpoints, and some pickle evaluation files for this project are available for download at https://nps.app.box.com/folder/260201116211 due to GitHub storage limits.

## Dataset
The coastal dataset is available on the box site along with the out of distribution datasets used for visualizations in the paper (Alaska, Florida, and Orange Cable).

## Explanation of folders in this repo

### trainers
Contains code for performing transfer learning from ImageNet-1K to coastal dataset with the ResNet50 Deterministic, MC Dropout, and VI Flipout models. There is a bash script in each folder that was used to run the training process on a GPU framework. The train .sh file launches the Python code task.py and also contains all of the customizable hyperparameters such as number of epochs, learning rate, etc. for each training. Task.py contains the main driver code for the training, and other information such as model, dataset, and callbacks are all contained in their respective Python files in the same folder. This was done simply for the purpose of clean code organization. The task.py files load model weights from the provided ImageNet checkpoint and then perform training on the coastal dataset. There is an option to perform either fixed-feature training (where all layers except final classification head remain frozen while transfer learning occurs on the coastal dataset), or fine-tuning training (where a specified number of layers are unfrozen and allowed to train on coastal data). This is controlled by the "training" hyperparameter in the train.sh files. The code contains callbacks to incrementally save model checkpoints as training progresses and will output a log file to display the training progress. Most training code ran in a few hours when using GPU support. The model checkpoints produced can be loaded to produce the various visualizations depicted in the paper and discussed below.
### model_evaluations_into_pickle
Provides code for evaluating various metrics on test data and storing this data into pickle files for visualizations. This folder is broken into various subfolders depending on which dataset the model to be evaluated was trained on. For example, to run the evaluations for MC Dropout on the coastal dataset and generate the prediction data to be put in a pickle file, run the dropout_eval_to_pickle.sh, which calls the file eval_multiple_to_pickle.py. This file loads the MC Dropout model checkpoint that was trained by performing transfer learning from ImageNet to the coastal dataset and runs an evaluation on the coastal test set. It puts the true label/predicted label data into the Pickle file. Once the pickle file has been generated, you can copy that path and use it as input for the functions discussed below that produce useful calculations (these are performed using the model_metrics.py file) and visualizations to better understand the role uncertainty plays in this project.

### classification_reports
This folder contains code to produce an sklearn classification report. You pass in the Pickle file path (which contains true labels and predicted labels), and it will produce the classification report depicted in the paper.

### calibration_curves
This folder contains code to generate the calibration curves across the various models. This code in plot_calibration_curves.py takes the Pickle file path as input and then calculates the values used is the calibration curve, which are then plotted. 
### grad_cam 
Contains code to plot all eight Grad-CAM figures together (as depicted in the paper). The innerworkings of the Grad-CAM algorithm are shown and explained in the follow_along_notebook.
### uncertainty_bar_plots
Contains code for epistemic uncertainty bar plots across different datasets. The uncertainty values in this file, depicted as Python lists, are generated by running the code in model_evaluations_into_pickle and then printing out the uncertainty values in order to plot them. For example, to get the uncertainty bar plot values for MC Dropout on the coastal dataset, you would run the eval_multiple_to_pickle.py file in model_evaluations_into_pickle/resnet_mcdropout/coastal to generate a Pickle file with the evaluation metrics, and then you can run print_multiple_from_pickle.py in that same folder to calulate uncertainty metrics from the true label/predicted label info in the picke file and print out the metrics. Then, you can use those values to generate the uncertainty bar plots. This workflow is also demonstrated in the follow_along_notebook. 
### ECE
Contains code for generating the Expected Calibration Error for the various models. The code in ece.py takes a Pickle file as input and will print out ECE metrics for that Pickle data. 
### most_and_least_uncertain
Contains code for generating the ten most uncertain and ten least uncertain images from a given dataset, as shown in the paper appendix. The most and least uncertain images were determined for both the coastal dataset and ImageNet for the MC Dropout model. This code receives as input a Pickle file and sorts the images by normal entropy and then can output the ten images with the highest or lowest normal entropy for viewing. 
### follow_along_notebook
proj_notebook.ipynb contains code to load the test dataset, checkpoints, and then run some key visualizations on the data along with explanations. This code includes Grad-CAM ensemble visualizations, a model evaluation into Pickle demonstration, a calibration curve plot, classification report summary, and an uncertainty bar plot visualization. The purpose of this file is to show a simple demonstration of the key components of the paper in a single file. 

## Setup Instructions
Due to Tensorflow compatibility issues, we had to use a few different conda environments for various parts of the code. The exact setup of these different environments are all included in the setup_files folder of this repo. The thesis_work environment should function for all code dealing with MC Dropout and deterministic models. The thesis_work environment is also used to run the Jupyter Notebook walk through. The VI_flipout environment should function for all code dealing with flipout model training and evaluation. The ViT2 model should function for all code dealing with the Vision Transformers. 


## Basic Pipeline

1. The first step in this project is to perform transfer learning from ImageNet-1K to the coastal dataset. This work is contained in the trainers/ folder. The task.py file in each model folder under trainers/ is the driver code for this process. This training process uses the coastal dataset to train on, and this dataset is available on the box site. The train .sh file launches the Python code task.py and also contains all of the customizable hyperparameters for each training. The task.py files load model weights from the provided ImageNet checkpoint and then perform training on the coastal dataset. There is an option to perform either fixed-feature training (where all layers except final classification head remain frozen while transfer learning occurs on the coastal dataset), or fine-tuning training (where a specified number of layers are unfrozen and allowed to train on coastal data). This is controlled by the "training" hyperparameter in the train.sh files.  To run the transfer learning, run the files such as train_mcdropout.sh or train_resnet50_flipout.sh, found in the subdirectories of the trainers/ folder. This will save model checkpoints throughout the training process and output training logs (a .txt file) to view incremental training progress. The code includes callbacks to save model checkpoints as the networks learns. All of the file model checkpoint file paths, log file paths, and file paths to the training data will need to be updated to match your personal setup. The model checkpoints produced can be loaded to produce the various visualizations depicted in the paper.
2. After performing the transfer learning from ImageNet-1K to coastal dataset (or downloading a pre-trained coastal checkpoint available on Box), you can then run model evaluations and calculate uncertainty metrics for visualizations. These evaluation files are in the folder model_evaluations_into_pickle. To generate a new pickle file with evaluation metrics, the files titled "eval_multiple_to_pickle.py" can be run by passing the respecting model checkpoint (MC Dropout or VI Flipout) as input. This will produce a Pickle file that contains the true/predicted label information. This Pickle file can then be loaded in other files (discussed below) to calcualte uncertainty metrics and other key data for visualizations. 
4. With a Pickle file ready, you can then calculate and print out uncertainty metrics (for example model_evaluations_into_pickle/resnet_mcdropout/coastal/print_multiple_from_pickle.py) or you can use this Pickle file to generate visualziaitons such as the calibration curve or the classification reports. The uncertainty metrics in this project all use functionality from the model_metrics.py file to calculate things such as epistemic and aleatoric uncertainty and entropy. The specific visualization are discussed above in the "Explanation of folders in this repo" section.
5. Beyond this, the follow_along_notebook folder contains a simple Jupyter notebook that contains code with a model evaluation and some key visualizations.

## Cite

L. Rombado, M. Orescanin and M. Orescanin, "Uncertainty-Aware Aerial Coastal Imagery Pattern Recognition Through Transfer Learning with ImageNet-1K Variational Embeddings," in IEEE Access, doi: 10.1109/ACCESS.2024.3451373. 




